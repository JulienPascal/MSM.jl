<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Getting started · MSM.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">MSM.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../installation/">Installation</a></li><li class="is-active"><a class="tocitem" href>Getting started</a><ul class="internal"><li><a class="tocitem" href="#Example-in-serial"><span>Example in serial</span></a></li><li><a class="tocitem" href="#Example-in-parallel"><span>Example in parallel</span></a></li></ul></li><li><a class="tocitem" href="../functions/">Functions and Types</a></li><li><a class="tocitem" href="../references/">References</a></li><li><a class="tocitem" href="../contributing/">Contributing</a></li><li><a class="tocitem" href="../license/">License</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Getting started</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Getting started</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JulienPascal/MSM.jl/blob/master/docs/src/gettingstarted.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Getting-Started"><a class="docs-heading-anchor" href="#Getting-Started">Getting Started</a><a id="Getting-Started-1"></a><a class="docs-heading-anchor-permalink" href="#Getting-Started" title="Permalink"></a></h1><p>Our overarching goal is to find the parameter values <span>$\theta_{MSM}$</span> minimizing the following function:</p><p class="math-container">\[g(\theta; m*, W) = (m(\theta) - m*)&#39; W (m(\theta) - m*)\]</p><p>where <span>$m*$</span> is a vector of empirical moments, <span>$m(\theta)$</span> is a vector of moments calculated using simulated data, and <span>$W$</span> is carefully chosen weighting matrix. We also want to build confidence intervals for <span>$\theta_{MSM}$</span>.</p><p>While simple in theory (it is just a function minimization, right?), in practice many bad things can happen. The function <span>$g$</span> may fail in some areas of the parameter space; <span>$g$</span> may be stuck in some local minima; <span>$g$</span> is really slow and you do not have a strong prior regarding good starting values. <a href="https://github.com/JulienPascal/MSM.jl">MSM.jl</a> uses minimization algorithms that are robust to the problems mentioned above. You may choose between two options:</p><ol><li>Global minimization algorithms from <a href="https://github.com/robertfeldt/BlackBoxOptim.jl">BlackBoxOptim</a></li><li>A multistart algorithm using several local optimization routines from <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a></li></ol><p>Let&#39;s follow a learning-by-doing approach. As a warm-up, let&#39;s first estimate parameters in serial. In a second step, we use several workers on a cluster.</p><h2 id="Example-in-serial"><a class="docs-heading-anchor" href="#Example-in-serial">Example in serial</a><a id="Example-in-serial-1"></a><a class="docs-heading-anchor-permalink" href="#Example-in-serial" title="Permalink"></a></h2><p>In a real-world scenario, you would probably use empirical data. Here, let&#39;s simulate a fake dataset.</p><pre><code class="language-julia">using MSM
using DataStructures
using OrderedCollections
using Random
using Distributions
using Statistics
using LinearAlgebra
using Distributed
using Plots
Random.seed!(1234)  #for replicability reasons
T = 100000          #number of periods
P = 2               #number of dependent variables
beta0 = rand(P)     #choose true coefficients by drawing from a uniform distribution on [0,1]
alpha0 = rand(1)[]  #intercept
theta0 = 0.0 #coefficient to create serial correlation in the error terms

# Generation of error terms
# row = individual dimension
# column = time dimension
U = zeros(T)
d = Normal()
U[1] = rand(d, 1)[] #first error term
for t = 2:T
    U[t] = rand(d, 1)[] + theta0*U[t-1]
end

# Let&#39;s simulate the dependent variables x_t
x = zeros(T, P)
d = Uniform(0, 5)
for p = 1:P
    x[:,p] = rand(d, T)
end

# Let&#39;s calculate the resulting y_t
y = zeros(T)
for t=1:T
    y[t] = alpha0 + x[t,1]*beta0[1] + x[t,2]*beta0[2] + U[t]
end

# Visualize data
p1 = scatter(x[1:100,1], y[1:100], xlabel = &quot;x1&quot;, ylabel = &quot;y&quot;, legend=:none, smooth=true)
p2 = scatter(x[1:100,2], y[1:100], xlabel = &quot;x2&quot;, ylabel = &quot;y&quot;, legend=:none, smooth=true)
p = plot(p1, p2);</code></pre><p><img src="../f-fake-data.png" alt/></p><h3 id="Step-1:-Initializing-a-MSMProblem"><a class="docs-heading-anchor" href="#Step-1:-Initializing-a-MSMProblem">Step 1: Initializing a MSMProblem</a><a id="Step-1:-Initializing-a-MSMProblem-1"></a><a class="docs-heading-anchor-permalink" href="#Step-1:-Initializing-a-MSMProblem" title="Permalink"></a></h3><pre><code class="language-julia"># Select a global optimizer (see BlackBoxOptim.jl) and a local minimizer (see Optim.jl):
myProblem = MSMProblem(options = MSMOptions(maxFuncEvals=10000, globalOptimizer = :dxnes, localOptimizer = :LBFGS));</code></pre><pre class="documenter-example-output">MSMProblem(0, OrderedDict{String, Vector{Float64}}(), [1.0], OrderedDict{String, Vector{Float64}}(), OrderedDict{String, Float64}(), 0.0, MSM.default_function, MSM.default_function, MSM.default_function, MSMOptions(:dxnes, :LBFGS, 10000, &quot;2021-06-14--15h-31m-11s&quot;, false, false, 50, 999999.0, :LHC, false, 20, 99999.9), BlackBoxOptim.OptController{BlackBoxOptim.DXNESOpt{Float64, BlackBoxOptim.RandomBound{BlackBoxOptim.ContinuousRectSearchSpace}}, BlackBoxOptim.FunctionBasedProblem{BlackBoxOptim.ScalarFitnessScheme{true}, BlackBoxOptim.ContinuousRectSearchSpace, Nothing}}(BlackBoxOptim.DXNESOpt{Float64, BlackBoxOptim.RandomBound{BlackBoxOptim.ContinuousRectSearchSpace}}(BlackBoxOptim.RandomBound{BlackBoxOptim.ContinuousRectSearchSpace}(BlackBoxOptim.ContinuousRectSearchSpace([-5.0, -5.0], [5.0, 5.0], [10.0, 10.0])), 4, [0.48042271030918515, 0.01957728969081496, -0.25, -0.25], [-0.25, -0.25, 0.01957728969081496, 0.48042271030918515], 1.0, 0.03571428571428571, 1.5, 1.0e10, 1.8163974448785931, 0.7016420088558287, 0.9151637747160076, 1.0039720770839917, [NaN, NaN], [-0.014081941923999183 0.007303209450709972; 0.0073032094507099726 0.01408194192399918], 1.693331806535492, [0.25809033252501146, 2.5338708030134605], [-0.8041880459049802 0.5216151539497828 0.8041880459049802 -0.5216151539497828; 0.522743019666237 2.596793788233121 -0.522743019666237 -2.596793788233121], BlackBoxOptim.Candidate{Float64}[BlackBoxOptim.Candidate{Float64}([-0.09931610075524533, 1.9747538181420485], 4, 387.2878182937347, nothing, 0), BlackBoxOptim.Candidate{Float64}([1.2264870990995176, 4.048804586708933], 3, 647.516615191048, nothing, 0), BlackBoxOptim.Candidate{Float64}([0.9439142071443202, 4.71288583499769], 2, 1460.7041297911062, nothing, 0), BlackBoxOptim.Candidate{Float64}([-0.38188899271044274, 4.888455377939379], 1, 2251.1504357017457, nothing, 0)], [0.4222990531945374, 4.571547606375169], [6.9120580632391e-310, 6.9120580711908e-310], [-0.16420872066952594, -2.037676803361709], [-0.014081941923999183 0.007303209450709972; 0.0073032094507099726 0.01408194192399918], [0.20104701147624504 -0.1304037884874457 0.015743822340572197 -0.2505957659988975; -0.13068575491655926 -0.6491984470582802 -0.010233891529857304 -1.2475587098570122], [-0.8041880459049802 0.5216151539497828 0.8041880459049802 -0.5216151539497828; 0.522743019666237 2.596793788233121 -0.522743019666237 -2.596793788233121]), BlackBoxOptim.FunctionBasedProblem{BlackBoxOptim.ScalarFitnessScheme{true}, BlackBoxOptim.ContinuousRectSearchSpace, Nothing}(MSM.var&quot;#3#4&quot;(), &quot;&lt;unknown&gt;&quot;, BlackBoxOptim.ScalarFitnessScheme{true}(), BlackBoxOptim.ContinuousRectSearchSpace([-5.0, -5.0], [5.0, 5.0], [10.0, 10.0]), nothing), BlackBoxOptim.ParamsDictChain[BlackBoxOptim.ParamsDictChain[Dict{Symbol, Any}(:RngSeed =&gt; 196850, :NumDimensions =&gt; 2, :SearchRange =&gt; (-5.0, 5.0), :TraceMode =&gt; :silent, :Method =&gt; :dxnes, :MaxFuncEvals =&gt; 2, :MaxSteps =&gt; 0),Dict{Symbol, Any}()],Dict{Symbol, Any}(:CallbackInterval =&gt; -1.0, :TargetFitness =&gt; nothing, :TraceMode =&gt; :compact, :FitnessScheme =&gt; BlackBoxOptim.ScalarFitnessScheme{true}(), :MinDeltaFitnessTolerance =&gt; 1.0e-50, :NumDimensions =&gt; :NotSpecified, :FitnessTolerance =&gt; 1.0e-8, :TraceInterval =&gt; 0.5, :MaxStepsWithoutProgress =&gt; 10000, :MaxSteps =&gt; 10000…)], BlackBoxOptim.OptRunController{BlackBoxOptim.DXNESOpt{Float64, BlackBoxOptim.RandomBound{BlackBoxOptim.ContinuousRectSearchSpace}}, E} where E&lt;:BlackBoxOptim.Evaluator[BlackBoxOptim.OptRunController{BlackBoxOptim.DXNESOpt{Float64, BlackBoxOptim.RandomBound{BlackBoxOptim.ContinuousRectSearchSpace}}, BlackBoxOptim.ProblemEvaluator{Float64, Float64, BlackBoxOptim.TopListArchive{Float64, BlackBoxOptim.ScalarFitnessScheme{true}}, BlackBoxOptim.FunctionBasedProblem{BlackBoxOptim.ScalarFitnessScheme{true}, BlackBoxOptim.ContinuousRectSearchSpace, Nothing}}}(BlackBoxOptim.DXNESOpt{Float64, BlackBoxOptim.RandomBound{BlackBoxOptim.ContinuousRectSearchSpace}}(BlackBoxOptim.RandomBound{BlackBoxOptim.ContinuousRectSearchSpace}(BlackBoxOptim.ContinuousRectSearchSpace([-5.0, -5.0], [5.0, 5.0], [10.0, 10.0])), 4, [0.48042271030918515, 0.01957728969081496, -0.25, -0.25], [-0.25, -0.25, 0.01957728969081496, 0.48042271030918515], 1.0, 0.03571428571428571, 1.5, 1.0e10, 1.8163974448785931, 0.7016420088558287, 0.9151637747160076, 1.0039720770839917, [NaN, NaN], [-0.014081941923999183 0.007303209450709972; 0.0073032094507099726 0.01408194192399918], 1.693331806535492, [0.25809033252501146, 2.5338708030134605], [-0.8041880459049802 0.5216151539497828 0.8041880459049802 -0.5216151539497828; 0.522743019666237 2.596793788233121 -0.522743019666237 -2.596793788233121], BlackBoxOptim.Candidate{Float64}[BlackBoxOptim.Candidate{Float64}([-0.09931610075524533, 1.9747538181420485], 4, 387.2878182937347, nothing, 0), BlackBoxOptim.Candidate{Float64}([1.2264870990995176, 4.048804586708933], 3, 647.516615191048, nothing, 0), BlackBoxOptim.Candidate{Float64}([0.9439142071443202, 4.71288583499769], 2, 1460.7041297911062, nothing, 0), BlackBoxOptim.Candidate{Float64}([-0.38188899271044274, 4.888455377939379], 1, 2251.1504357017457, nothing, 0)], [0.4222990531945374, 4.571547606375169], [6.9120580632391e-310, 6.9120580711908e-310], [-0.16420872066952594, -2.037676803361709], [-0.014081941923999183 0.007303209450709972; 0.0073032094507099726 0.01408194192399918], [0.20104701147624504 -0.1304037884874457 0.015743822340572197 -0.2505957659988975; -0.13068575491655926 -0.6491984470582802 -0.010233891529857304 -1.2475587098570122], [-0.8041880459049802 0.5216151539497828 0.8041880459049802 -0.5216151539497828; 0.522743019666237 2.596793788233121 -0.522743019666237 -2.596793788233121]), BlackBoxOptim.ProblemEvaluator{Float64, Float64, BlackBoxOptim.TopListArchive{Float64, BlackBoxOptim.ScalarFitnessScheme{true}}, BlackBoxOptim.FunctionBasedProblem{BlackBoxOptim.ScalarFitnessScheme{true}, BlackBoxOptim.ContinuousRectSearchSpace, Nothing}}(BlackBoxOptim.FunctionBasedProblem{BlackBoxOptim.ScalarFitnessScheme{true}, BlackBoxOptim.ContinuousRectSearchSpace, Nothing}(MSM.var&quot;#3#4&quot;(), &quot;&lt;unknown&gt;&quot;, BlackBoxOptim.ScalarFitnessScheme{true}(), BlackBoxOptim.ContinuousRectSearchSpace([-5.0, -5.0], [5.0, 5.0], [10.0, 10.0]), nothing), BlackBoxOptim.TopListArchive{Float64, BlackBoxOptim.ScalarFitnessScheme{true}}(BlackBoxOptim.ScalarFitnessScheme{true}(), 1.622648390773828e9, 2, 4, 10, BlackBoxOptim.TopListIndividual{Float64}[BlackBoxOptim.TopListIndividual{Float64}([-0.09931610075524533, 1.9747538181420485], 387.2878182937347, 0), BlackBoxOptim.TopListIndividual{Float64}([1.2264870990995176, 4.048804586708933], 647.516615191048, 0), BlackBoxOptim.TopListIndividual{Float64}([0.9439142071443202, 4.71288583499769], 1460.7041297911062, 0), BlackBoxOptim.TopListIndividual{Float64}([-0.38188899271044274, 4.888455377939379], 2251.1504357017457, 0)], BlackBoxOptim.TopListFitness{Float64}[BlackBoxOptim.TopListFitness{Float64}(2251.1504357017457, NaN, 1, 1.622648393824736e9), BlackBoxOptim.TopListFitness{Float64}(1460.7041297911062, 0.3511299348878191, 2, 1.622648393824752e9), BlackBoxOptim.TopListFitness{Float64}(647.516615191048, 0.5567092596064278, 3, 1.622648393824754e9), BlackBoxOptim.TopListFitness{Float64}(387.2878182937347, 0.40188744318249425, 4, 1.622648393824756e9)]), 4, 387.2878182937347), :silent, false, 0.5, BlackBoxOptim.var&quot;#80#81&quot;(), -1.0, 0, 2, 100, 10000, 0.0, 1.0e-50, 1.0e-8, 1, 0, 0, 1, 4, 0, 1.622648393813614e9, 1.6226483938248e9, 1.622648393813615e9, -1.0, &quot;Max number of function evaluations (2) reached&quot;)]), BlackBoxOptim.OptimizationResults(&quot;dxnes&quot;, &quot;Max number of function evaluations (2) reached&quot;, 1, 1.622648393813614e9, 0.01118612289428711, BlackBoxOptim.ParamsDictChain[BlackBoxOptim.ParamsDictChain[Dict{Symbol, Any}(:RngSeed =&gt; 196850, :NumDimensions =&gt; 2, :SearchRange =&gt; (-5.0, 5.0), :TraceMode =&gt; :silent, :Method =&gt; :dxnes, :MaxFuncEvals =&gt; 2, :MaxSteps =&gt; 0),Dict{Symbol, Any}()],Dict{Symbol, Any}(:CallbackInterval =&gt; -1.0, :TargetFitness =&gt; nothing, :TraceMode =&gt; :compact, :FitnessScheme =&gt; BlackBoxOptim.ScalarFitnessScheme{true}(), :MinDeltaFitnessTolerance =&gt; 1.0e-50, :NumDimensions =&gt; :NotSpecified, :FitnessTolerance =&gt; 1.0e-8, :TraceInterval =&gt; 0.5, :MaxStepsWithoutProgress =&gt; 10000, :MaxSteps =&gt; 10000…)], 4, BlackBoxOptim.ScalarFitnessScheme{true}(), BlackBoxOptim.TopListArchiveOutput{Float64, Vector{Float64}}(387.2878182937347, [-0.09931610075524533, 1.9747538181420485]), BlackBoxOptim.PopulationOptimizerOutput{Vector{BlackBoxOptim.Candidate{Float64}}}(BlackBoxOptim.Candidate{Float64}[BlackBoxOptim.Candidate{Float64}([-0.09931610075524533, 1.9747538181420485], 4, 387.2878182937347, nothing, 0), BlackBoxOptim.Candidate{Float64}([1.2264870990995176, 4.048804586708933], 3, 647.516615191048, nothing, 0), BlackBoxOptim.Candidate{Float64}([0.9439142071443202, 4.71288583499769], 2, 1460.7041297911062, nothing, 0), BlackBoxOptim.Candidate{Float64}([-0.38188899271044274, 4.888455377939379], 1, 2251.1504357017457, nothing, 0)])),  * Status: success

 * Candidate solution
    Final objective value:     5.378388e-17

 * Found with
    Algorithm:     L-BFGS

 * Convergence measures
    |x - x&#39;|               = 4.54e-11 ≰ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 4.54e-11 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 2.85e-19 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 5.30e-03 ≰ 0.0e+00
    |g(x)|                 = 9.88e-14 ≤ 1.0e-08

 * Work counters
    Seconds run:   0  (vs limit Inf)
    Iterations:    24
    f(x) calls:    67
    ∇f(x) calls:   67
, Matrix{Float64}(undef, 0, 0), Matrix{Float64}(undef, 0, 0))</pre><h3 id="Step-2.-Set-empirical-moments-and-weight-matrix"><a class="docs-heading-anchor" href="#Step-2.-Set-empirical-moments-and-weight-matrix">Step 2. Set empirical moments and weight matrix</a><a id="Step-2.-Set-empirical-moments-and-weight-matrix-1"></a><a class="docs-heading-anchor-permalink" href="#Step-2.-Set-empirical-moments-and-weight-matrix" title="Permalink"></a></h3><p>Choose the set of empirical moments to match and the weight matrix <span>$W$</span> using the functions <code>set_empirical_moments!</code> and <code>set_weight_matrix!</code></p><pre><code class="language-julia">dictEmpiricalMoments = OrderedDict{String,Array{Float64,1}}()
dictEmpiricalMoments[&quot;mean&quot;] = [mean(y)] #informative on the intercept
dictEmpiricalMoments[&quot;mean_x1y&quot;] = [mean(x[:,1] .* y)] #informative on betas
dictEmpiricalMoments[&quot;mean_x2y&quot;] = [mean(x[:,2] .* y)] #informative on betas
dictEmpiricalMoments[&quot;mean_x1y^2&quot;] = [mean((x[:,1] .* y).^2)] #informative on betas
dictEmpiricalMoments[&quot;mean_x2y^2&quot;] = [mean((x[:,2] .* y).^2)] #informative on betas

W = Matrix(1.0 .* I(length(dictEmpiricalMoments)))#initialization
#Special case: diagonal matrix
#Sum of square percentage deviations from empirical moments
#(you may choose something else)
for (indexMoment, k) in enumerate(keys(dictEmpiricalMoments))
    W[indexMoment,indexMoment] = 1.0/(dictEmpiricalMoments[k][1])^2
end

set_empirical_moments!(myProblem, dictEmpiricalMoments)
set_weight_matrix!(myProblem, W)</code></pre><pre class="documenter-example-output">5×5 Matrix{Float64}:
 0.063999  0.0         0.0         0.0         0.0
 0.0       0.00817344  0.0         0.0         0.0
 0.0       0.0         0.00760982  0.0         0.0
 0.0       0.0         0.0         2.41806e-5  0.0
 0.0       0.0         0.0         0.0         2.0803e-5</pre><h3 id="Step-3.-Set-priors"><a class="docs-heading-anchor" href="#Step-3.-Set-priors">Step 3. Set priors</a><a id="Step-3.-Set-priors-1"></a><a class="docs-heading-anchor-permalink" href="#Step-3.-Set-priors" title="Permalink"></a></h3><p>Our &quot;prior&quot; belief regarding the parameter values is to be specified using <code>set_priors!()</code>. It is not fully a full-fledged prior probability distribution, but simply an initial guess for each parameter, as well as lower and upper bounds:</p><pre><code class="language-julia">dictPriors = OrderedDict{String,Array{Float64,1}}()
# Of the form: [initial_guess, lower_bound, upper_bound]
dictPriors[&quot;alpha&quot;] = [0.5, 0.001, 1.0]
dictPriors[&quot;beta1&quot;] = [0.5, 0.001, 1.0]
dictPriors[&quot;beta2&quot;] = [0.5, 0.001, 1.0]
set_priors!(myProblem, dictPriors)</code></pre><pre class="documenter-example-output">OrderedDict{String, Vector{Float64}} with 3 entries:
  &quot;alpha&quot; =&gt; [0.5, 0.001, 1.0]
  &quot;beta1&quot; =&gt; [0.5, 0.001, 1.0]
  &quot;beta2&quot; =&gt; [0.5, 0.001, 1.0]</pre><h3 id="Step-4:-Specifying-the-function-generating-simulated-moments"><a class="docs-heading-anchor" href="#Step-4:-Specifying-the-function-generating-simulated-moments">Step 4: Specifying the function generating simulated moments</a><a id="Step-4:-Specifying-the-function-generating-simulated-moments-1"></a><a class="docs-heading-anchor-permalink" href="#Step-4:-Specifying-the-function-generating-simulated-moments" title="Permalink"></a></h3><p>The objective function must generate an <strong>ordered dictionary</strong> containing the <strong>keys of dictEmpiricalMoments</strong>. Use <code>set_simulate_empirical_moments!</code> and <code>construct_objective_function!</code></p><p><strong>Remark:</strong> we &quot;freeze&quot; randomness during the minimization step. One way to do that is to generate draws from a Uniform([0,1]) outside of the objective function and to use <a href="https://en.wikipedia.org/wiki/Inverse_transform_sampling">inverse transform sampling</a> to generate draws from a normal distribution. Otherwise the objective function would be &quot;noisy&quot; and the minimization algorithms would have a hard time finding the global minimum.</p><pre><code class="language-julia"># x[1] corresponds to the intercept; x[2] corresponds to beta1; x[3] corresponds to beta2
function functionLinearModel(x; uniform_draws::Array{Float64,1}, simX::Array{Float64,2}, nbDraws::Int64 = length(uniform_draws), burnInPerc::Int64 = 0)
    T = nbDraws
    P = 2       #number of dependent variables
    alpha = x[1]
    beta = x[2:end]
    theta = 0.0     #coefficient to create serial correlation in the error terms

    # Creation of error terms
    # row = individual dimension
    # column = time dimension
    U = zeros(T)
    d = Normal()
    # Inverse cdf (i.e. quantile)
    gaussian_draws = quantile.(d, uniform_draws)
    U[1] = gaussian_draws[1] #first error term
    for t = 2:T
        U[t] = gaussian_draws[t] + theta*U[t-1]
    end

    # Let&#39;s calculate the resulting y_t
    y = zeros(T)
    for t=1:T
        y[t] = alpha + simX[t,1]*beta[1] + simX[t,2]*beta[2] + U[t]
    end

    # Get rid of the burn-in phase:
    #------------------------------
    startT = max(1, Int(nbDraws * (burnInPerc / 100)))

    # Moments:
    #---------
    output = OrderedDict{String,Float64}()
    output[&quot;mean&quot;] = mean(y[startT:nbDraws])
    output[&quot;mean_x1y&quot;] = mean(simX[startT:nbDraws,1] .* y[startT:nbDraws])
    output[&quot;mean_x2y&quot;] = mean(simX[startT:nbDraws,2] .* y[startT:nbDraws])
    output[&quot;mean_x1y^2&quot;] = mean((simX[startT:nbDraws,1] .* y[startT:nbDraws]).^2)
    output[&quot;mean_x2y^2&quot;] = mean((simX[startT:nbDraws,2] .* y[startT:nbDraws]).^2)

    return output
end

# Let&#39;s freeze the randomness during the minimization
d_Uni = Uniform(0,1)
nbDraws = 100000 #number of draws in the simulated data
uniform_draws = rand(d_Uni, nbDraws)
simX = zeros(length(uniform_draws), 2)
d = Uniform(0, 5)
for p = 1:2
  simX[:,p] = rand(d, length(uniform_draws))
end

# Attach the function parameters -&gt; simulated moments:
set_simulate_empirical_moments!(myProblem, x -&gt; functionLinearModel(x, uniform_draws = uniform_draws, simX = simX))

# Construct the objective (m-m*)&#39;W(m-m*):
construct_objective_function!(myProblem)</code></pre><pre class="documenter-example-output">(::MSM.var&quot;#objective_function_MSM#6&quot;{MSMProblem}) (generic function with 1 method)</pre><h3 id="Step-5.-Running-the-optimization"><a class="docs-heading-anchor" href="#Step-5.-Running-the-optimization">Step 5. Running the optimization</a><a id="Step-5.-Running-the-optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Step-5.-Running-the-optimization" title="Permalink"></a></h3><p>Use the global optimization algorithm specified in <code>globalOptimizer</code>:</p><pre><code class="language-julia"># Global optimization:
msm_optimize!(myProblem, verbose = false)</code></pre><pre class="documenter-example-output">(Any[4.476137659829206e-6], Any[[0.5794644818290314, 0.5816899850919506, 0.7650406518652915]])</pre><h3 id="Step-6.-Analysing-Results"><a class="docs-heading-anchor" href="#Step-6.-Analysing-Results">Step 6. Analysing Results</a><a id="Step-6.-Analysing-Results-1"></a><a class="docs-heading-anchor-permalink" href="#Step-6.-Analysing-Results" title="Permalink"></a></h3><h4 id="Step-6.A.-Point-estimates"><a class="docs-heading-anchor" href="#Step-6.A.-Point-estimates">Step 6.A. Point estimates</a><a id="Step-6.A.-Point-estimates-1"></a><a class="docs-heading-anchor-permalink" href="#Step-6.A.-Point-estimates" title="Permalink"></a></h4><pre><code class="language-julia">minimizer = msm_minimizer(myProblem)
minimum_val = msm_minimum(myProblem)
println(&quot;Minimum objective function = $(minimum_val)&quot;)
println(&quot;Estimated value for alpha = $(minimizer[1]). True value for beta1 = $(alpha0[1])&quot;)
println(&quot;Estimated value for beta1 = $(minimizer[2]). True value for beta1 = $(beta0[1])&quot;)
println(&quot;Estimated value for beta2 = $(minimizer[3]). True value for beta2 = $(beta0[2])&quot;)</code></pre><pre class="documenter-example-output">Minimum objective function = 4.476137659829206e-6
Estimated value for alpha = 0.5794644818290314. True value for beta1 = 0.5662374165061859
Estimated value for beta1 = 0.5816899850919506. True value for beta1 = 0.5908446386657102
Estimated value for beta2 = 0.7650406518652915. True value for beta2 = 0.7667970365022592</pre><h4 id="Step-6.B.-Inference"><a class="docs-heading-anchor" href="#Step-6.B.-Inference">Step 6.B. Inference</a><a id="Step-6.B.-Inference-1"></a><a class="docs-heading-anchor-permalink" href="#Step-6.B.-Inference" title="Permalink"></a></h4><h5 id="Estimation-of-the-distance-matrix-\\Sigma_0"><a class="docs-heading-anchor" href="#Estimation-of-the-distance-matrix-\\Sigma_0">Estimation of the distance matrix <span>$\Sigma_0$</span></a><a id="Estimation-of-the-distance-matrix-\\Sigma_0-1"></a><a class="docs-heading-anchor-permalink" href="#Estimation-of-the-distance-matrix-\\Sigma_0" title="Permalink"></a></h5><p>Let&#39;s calculate the variance-covariance matrix of the <strong>&quot;distance matrix&quot;</strong> (using the terminolgy of <a href="https://www.jstor.org/stable/2951768?seq=1">Duffie and Singleton (1993)</a>). Here we know that errors are not correlated (the serial correlation coefficient is set to 0 in the code above). in the presence of serial correlation, an HAC estimation would be needed.</p><pre><code class="language-julia"># Empirical Series
#-----------------
X = zeros(T, 5)
X[:,1] = y
X[:,2] = (x[:,1] .* y)
X[:,3] = (x[:,2] .* y)
X[:,4] = (x[:,1] .* y).^2
X[:,5] = (x[:,2] .* y).^2
Sigma0 = cov(X)</code></pre><pre class="documenter-example-output">5×5 Matrix{Float64}:
   2.942     12.1631    13.6279    346.754    392.581
  12.1631    81.0139    47.795    2369.6     1503.16
  13.6279    47.795     87.8405   1490.87    2622.29
 346.754   2369.6     1490.87    77664.1    50175.4
 392.581   1503.16    2622.29    50175.4    87292.2</pre><h5 id="Asymptotic-variance"><a class="docs-heading-anchor" href="#Asymptotic-variance">Asymptotic variance</a><a id="Asymptotic-variance-1"></a><a class="docs-heading-anchor-permalink" href="#Asymptotic-variance" title="Permalink"></a></h5><h6 id="Theory"><a class="docs-heading-anchor" href="#Theory">Theory</a><a id="Theory-1"></a><a class="docs-heading-anchor-permalink" href="#Theory" title="Permalink"></a></h6><p>The asymptotic variance of the MSM estimate is calculated using the usual <strong>GMM sandwich formula</strong>, corrected to take into account simulation noise.</p><p class="math-container">\[AsymptoticVarianceMSM = (1 + \tau)*AsymptoticVarianceGMM\]</p><p>Here we are trying to match unconditional moments from time series. In this case, <span>$\tau = \frac{tData}{tSimulation}$</span>, where <span>$tData$</span> is the number of periods in the empirical data and <span>$tSimulation$</span> is the number of time periods in the simulated data.</p><p>See <a href="https://www.jstor.org/stable/2951768?seq=1">Duffie and Singleton (1993)</a> and <a href="https://www.jstor.org/stable/3533164?seq=1">Gouriéroux and Montfort (1996)</a> for details on how to choose <span>$\tau$</span>.</p><h6 id="Practice"><a class="docs-heading-anchor" href="#Practice">Practice</a><a id="Practice-1"></a><a class="docs-heading-anchor-permalink" href="#Practice" title="Permalink"></a></h6><p>Calculating the asymptotic variance using MSM.jl is done in two steps:</p><ul><li>setting the value of the <strong>&quot;distance matrix&quot;</strong> using the function <code>set_Sigma0!</code></li><li>calculating the asymptotic variance using the function <code>calculate_Avar!</code></li></ul><pre><code class="language-julia">set_Sigma0!(myProblem, Sigma0)
calculate_Avar!(myProblem, minimizer, tau = T/nbDraws) # nbDraws = number of draws in the simulated data</code></pre><pre class="documenter-example-output">3×3 Symmetric{Float64, Matrix{Float64}}:
  52.0137   -11.87     -8.70017
 -11.87       7.56734  -2.28552
  -8.70017   -2.28552   6.63646</pre><h4 id="Step-6.C.-Summarizing-the-results"><a class="docs-heading-anchor" href="#Step-6.C.-Summarizing-the-results">Step 6.C. Summarizing the results</a><a id="Step-6.C.-Summarizing-the-results-1"></a><a class="docs-heading-anchor-permalink" href="#Step-6.C.-Summarizing-the-results" title="Permalink"></a></h4><p>Once the asymptotic variance has been calculated, a summary table can be obtained using the function <code>summary_table</code>. This function has four inputs:</p><ol><li>a MSMProblem</li><li>the minimizer of the objective function</li><li>the length of the empirical sample</li><li>the confidence level associated to the test <strong>H0:</strong> <span>$\theta_i = 0$</span>,  <strong>H1:</strong> <span>$\theta_i != 0$</span></li></ol><pre><code class="language-julia">df = summary_table(myProblem, minimizer, T, 0.05)</code></pre><table class="data-frame"><thead><tr><th></th><th>Estimate</th><th>StdError</th><th>tValue</th><th>pValue</th><th>ConfIntervalLower</th><th>ConfIntervalUpper</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>3 rows × 6 columns</p><tr><th>1</th><td>0.579464</td><td>0.0228065</td><td>25.4078</td><td>0.0</td><td>0.541951</td><td>0.616978</td></tr><tr><th>2</th><td>0.58169</td><td>0.00869905</td><td>66.8683</td><td>0.0</td><td>0.567381</td><td>0.595999</td></tr><tr><th>3</th><td>0.765041</td><td>0.00814645</td><td>93.911</td><td>0.0</td><td>0.751641</td><td>0.77844</td></tr></tbody></table><h3 id="Step-7.-Identification-checks"><a class="docs-heading-anchor" href="#Step-7.-Identification-checks">Step 7. Identification checks</a><a id="Step-7.-Identification-checks-1"></a><a class="docs-heading-anchor-permalink" href="#Step-7.-Identification-checks" title="Permalink"></a></h3><p><strong>Local</strong> identification requires that the Jacobian matrix of the function <span>$f(\theta) -&gt; m(\theta)$</span> to be <strong>full column rank</strong> in a neighborhood of the solution:</p><pre><code class="language-julia">D = calculate_D(myProblem, minimizer)
println(&quot;number of parameters: $(size(D,2))&quot;)
println(&quot;rank of D is: $(rank(D))&quot;)</code></pre><pre class="documenter-example-output">number of parameters: 3
rank of D is: 3</pre><p>Local identification can also be visually checked by inspecting slices of the objective function in a neighborhood of the estimated value:</p><pre><code class="language-julia">vXGrid, vYGrid = msm_slices(myProblem, minimizer, nbPoints = 7);

using LaTeXStrings;
p1 = plot(vXGrid[:, 1],vYGrid[:, 1],title = L&quot;\alpha&quot;, label = &quot;&quot;,linewidth = 3, xrotation = 45);
plot!(p1, [minimizer[1]], seriestype = :vline, label = &quot;&quot;,linewidth = 1);
p2 = plot(vXGrid[:, 2],vYGrid[:, 2],title = L&quot;\beta_1&quot;, label = &quot;&quot;,linewidth = 3, xrotation = 45);
plot!(p2, [minimizer[2]], seriestype = :vline, label = &quot;&quot;,linewidth = 1);
p3 = plot(vXGrid[:, 3],vYGrid[:, 3],title = L&quot;\beta_2&quot;, label = &quot;&quot;,linewidth = 3, xrotation = 45);
plot!(p3, [minimizer[3]], seriestype = :vline, label = &quot;&quot;,linewidth = 1);
plot_combined = plot(p1, p2, p3);</code></pre><pre class="documenter-example-output">[ Info: slicing along alpha
[ Info: slicing along beta1
[ Info: slicing along beta2</pre><p><img src="../slices.png" alt/></p><h2 id="Example-in-parallel"><a class="docs-heading-anchor" href="#Example-in-parallel">Example in parallel</a><a id="Example-in-parallel-1"></a><a class="docs-heading-anchor-permalink" href="#Example-in-parallel" title="Permalink"></a></h2><p>To use the package on a cluster, one must make sure that empirical moments, priors and the weight matrix are defined for each worker. This can be done using <code>@everywhere begin end</code> blocks, or by using <a href="https://github.com/ChrisRackauckas/ParallelDataTransfer.jl">ParallelDataTransfer.jl</a>. The function returning simulated moments must also be defined <code>@everywhere</code>. See the file <a href="https://github.com/JulienPascal/MSM.jl/blob/main/notebooks/LinearModelCluster.jl">LinearModelCluster.jl</a> for details.</p><h3 id="Option-1:-Global-parallel-optimization"><a class="docs-heading-anchor" href="#Option-1:-Global-parallel-optimization">Option 1: Global parallel optimization</a><a id="Option-1:-Global-parallel-optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Option-1:-Global-parallel-optimization" title="Permalink"></a></h3><p>Choose a global optimizer that <strong>supports parallel evaluations</strong> (e.g. xnes or dxnes). See the <a href="https://github.com/robertfeldt/BlackBoxOptim.jl">documentation</a> for BlackBoxOptim.jl.</p><pre><code class="language-julia">msm_optimize!(myProblem, verbose = false)
minimizer = msm_minimizer(myProblem)
minimum_val = msm_minimum(myProblem)</code></pre><pre class="documenter-example-output">4.476137659829378e-6</pre><h3 id="Option-2:-Multistart-algorithm"><a class="docs-heading-anchor" href="#Option-2:-Multistart-algorithm">Option 2: Multistart algorithm</a><a id="Option-2:-Multistart-algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Option-2:-Multistart-algorithm" title="Permalink"></a></h3><p>The function <code>msm_multistart!</code> proceeds in two steps:</p><ol><li>It searches for starting values for which the model converges.</li><li>Several local optimization algorithms (specified with <code>localOptimizer</code>) are started in parallel using promising starting values from step 1</li></ol><p>The &quot;global&quot; minimum is the minimum of the local minima:</p><pre><code class="language-julia">msm_multistart!(myProblem, nums = nworkers(), verbose = false)
minimizer_multistart = msm_multistart_minimizer(myProblem)
minimum_multistart = msm_multistart_minimum(myProblem)</code></pre><pre class="documenter-example-output">4.476137659845412e-6</pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../installation/">« Installation</a><a class="docs-footer-nextpage" href="../functions/">Functions and Types »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 14 June 2021 15:33">Monday 14 June 2021</span>. Using Julia version 1.6.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
